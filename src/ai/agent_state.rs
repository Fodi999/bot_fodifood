//! 💾 Agent State Management
//! 
//! Persistent state management for AI agents to maintain memory
//! across restarts and track their decisions, performance, and learning.

use anyhow::Result;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::{Path, PathBuf};
use tokio::fs;
use chrono::{DateTime, Utc};

/// Persistent state for an AI agent
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentState {
    /// Agent identifier
    pub agent_id: String,
    /// Agent type (investor, business, cfo, etc.)
    pub agent_type: String,
    /// Current performance metrics
    pub performance: PerformanceMetrics,
    /// Historical decisions and their outcomes
    pub decision_history: Vec<AgentDecision>,
    /// Key performance indicators over time
    pub kpi_history: Vec<KPISnapshot>,
    /// Agent's learned preferences and strategies
    pub learned_strategies: HashMap<String, StrategyWeight>,
    /// State creation and last update times
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

/// Performance metrics for tracking agent effectiveness
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceMetrics {
    /// Success rate of decisions (0.0 - 1.0)
    pub success_rate: f64,
    /// Average ROI generated by agent decisions
    pub avg_roi: f64,
    /// Number of decisions made
    pub total_decisions: u64,
    /// Average response time in milliseconds
    pub avg_response_time_ms: u64,
    /// Accuracy score based on predictions vs outcomes
    pub accuracy_score: f64,
    /// Confidence level in current strategy
    pub confidence_level: f64,
}

/// Record of an agent's decision and its outcome
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentDecision {
    /// Unique decision identifier
    pub decision_id: String,
    /// Type of decision made
    pub decision_type: String,
    /// Input data used for decision
    pub input_data: serde_json::Value,
    /// Decision output/recommendation
    pub output: serde_json::Value,
    /// Confidence level at time of decision
    pub confidence: f64,
    /// Actual outcome/result
    pub outcome: Option<DecisionOutcome>,
    /// Timestamp of decision
    pub decided_at: DateTime<Utc>,
    /// When outcome was measured
    pub outcome_measured_at: Option<DateTime<Utc>>,
}

/// Outcome of a decision for learning purposes
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DecisionOutcome {
    /// Whether the decision was successful
    pub success: bool,
    /// Actual ROI or performance metric
    pub actual_value: f64,
    /// Predicted value at time of decision
    pub predicted_value: f64,
    /// Variance from prediction
    pub variance: f64,
    /// Lessons learned or insights
    pub insights: Vec<String>,
}

/// Key Performance Indicator snapshot at a point in time
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct KPISnapshot {
    /// Timestamp of snapshot
    pub timestamp: DateTime<Utc>,
    /// KPI values at this time
    pub kpis: HashMap<String, f64>,
    /// Context or market conditions
    pub context: HashMap<String, String>,
}

/// Weight and effectiveness of different strategies
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StrategyWeight {
    /// Strategy name or identifier
    pub strategy: String,
    /// Current weight/preference (0.0 - 1.0)
    pub weight: f64,
    /// Historical success rate with this strategy
    pub success_rate: f64,
    /// Number of times this strategy was used
    pub usage_count: u64,
    /// Last time this strategy was updated
    pub last_updated: DateTime<Utc>,
}

/// Agent state manager for persistence
pub struct AgentStateManager {
    /// Base directory for storing agent states
    base_dir: PathBuf,
}

impl AgentStateManager {
    /// Create new state manager
    pub async fn new(base_dir: &str) -> Result<Self> {
        let base_path = PathBuf::from(base_dir);
        
        // Create directory if it doesn't exist
        if !base_path.exists() {
            fs::create_dir_all(&base_path).await?;
            tracing::info!("📁 Created agent state directory: {}", base_path.display());
        }

        Ok(Self {
            base_dir: base_path,
        })
    }

    /// Save agent state to disk
    pub async fn save_state(&self, state: &AgentState) -> Result<()> {
        let file_path = self.get_state_file_path(&state.agent_id);
        let json_data = serde_json::to_string_pretty(state)?;
        
        fs::write(&file_path, json_data).await?;
        
        tracing::info!("💾 Saved state for agent {}", state.agent_id);
        Ok(())
    }

    /// Load agent state from disk
    pub async fn load_state(&self, agent_id: &str) -> Result<Option<AgentState>> {
        let file_path = self.get_state_file_path(agent_id);
        
        if !file_path.exists() {
            return Ok(None);
        }

        let json_data = fs::read_to_string(&file_path).await?;
        let state: AgentState = serde_json::from_str(&json_data)?;
        
        tracing::info!("📂 Loaded state for agent {}", agent_id);
        Ok(Some(state))
    }

    /// Create new agent state
    pub fn create_state(&self, agent_id: &str, agent_type: &str) -> AgentState {
        AgentState {
            agent_id: agent_id.to_string(),
            agent_type: agent_type.to_string(),
            performance: PerformanceMetrics {
                success_rate: 0.0,
                avg_roi: 0.0,
                total_decisions: 0,
                avg_response_time_ms: 0,
                accuracy_score: 0.0,
                confidence_level: 0.5,
            },
            decision_history: Vec::new(),
            kpi_history: Vec::new(),
            learned_strategies: HashMap::new(),
            created_at: Utc::now(),
            updated_at: Utc::now(),
        }
    }

    /// Update agent performance metrics
    pub async fn update_performance(&self, agent_id: &str, metrics: PerformanceMetrics) -> Result<()> {
        let mut state = self.load_state(agent_id).await?
            .unwrap_or_else(|| self.create_state(agent_id, "unknown"));
        
        state.performance = metrics;
        state.updated_at = Utc::now();
        
        self.save_state(&state).await?;
        Ok(())
    }

    /// Record a new decision
    pub async fn record_decision(&self, agent_id: &str, decision: AgentDecision) -> Result<()> {
        let mut state = self.load_state(agent_id).await?
            .unwrap_or_else(|| self.create_state(agent_id, "unknown"));
        
        state.decision_history.push(decision);
        state.performance.total_decisions += 1;
        state.updated_at = Utc::now();
        
        // Keep only last 1000 decisions to prevent infinite growth
        if state.decision_history.len() > 1000 {
            state.decision_history.drain(0..state.decision_history.len() - 1000);
        }
        
        self.save_state(&state).await?;
        Ok(())
    }

    /// Update decision outcome for learning
    pub async fn update_decision_outcome(&self, agent_id: &str, decision_id: &str, outcome: DecisionOutcome) -> Result<()> {
        let mut state = self.load_state(agent_id).await?
            .ok_or_else(|| anyhow::anyhow!("Agent state not found"))?;
        
        // Find and update the decision
        if let Some(decision) = state.decision_history.iter_mut().find(|d| d.decision_id == decision_id) {
            decision.outcome = Some(outcome.clone());
            decision.outcome_measured_at = Some(Utc::now());
            
            // Update performance metrics based on outcome
            let success_count = state.decision_history.iter()
                .filter_map(|d| d.outcome.as_ref())
                .filter(|o| o.success)
                .count();
            
            let total_outcomes = state.decision_history.iter()
                .filter(|d| d.outcome.is_some())
                .count();
            
            if total_outcomes > 0 {
                state.performance.success_rate = success_count as f64 / total_outcomes as f64;
                
                let avg_roi = state.decision_history.iter()
                    .filter_map(|d| d.outcome.as_ref())
                    .map(|o| o.actual_value)
                    .sum::<f64>() / total_outcomes as f64;
                
                state.performance.avg_roi = avg_roi;
                
                let accuracy_sum = state.decision_history.iter()
                    .filter_map(|d| d.outcome.as_ref())
                    .map(|o| 1.0 - (o.variance.abs() / o.actual_value.abs().max(1.0)))
                    .sum::<f64>();
                
                state.performance.accuracy_score = accuracy_sum / total_outcomes as f64;
            }
            
            state.updated_at = Utc::now();
            self.save_state(&state).await?;
            
            tracing::info!("📈 Updated decision outcome for agent {} decision {}", agent_id, decision_id);
        }
        
        Ok(())
    }

    /// Add KPI snapshot
    pub async fn add_kpi_snapshot(&self, agent_id: &str, kpis: HashMap<String, f64>, context: HashMap<String, String>) -> Result<()> {
        let mut state = self.load_state(agent_id).await?
            .unwrap_or_else(|| self.create_state(agent_id, "unknown"));
        
        let snapshot = KPISnapshot {
            timestamp: Utc::now(),
            kpis,
            context,
        };
        
        state.kpi_history.push(snapshot);
        state.updated_at = Utc::now();
        
        // Keep only last 500 snapshots
        if state.kpi_history.len() > 500 {
            state.kpi_history.drain(0..state.kpi_history.len() - 500);
        }
        
        self.save_state(&state).await?;
        Ok(())
    }

    /// Update strategy weights based on performance
    pub async fn update_strategy_weights(&self, agent_id: &str, strategy_updates: HashMap<String, f64>) -> Result<()> {
        let mut state = self.load_state(agent_id).await?
            .unwrap_or_else(|| self.create_state(agent_id, "unknown"));
        
        for (strategy, new_weight) in strategy_updates {
            let strategy_weight = state.learned_strategies.entry(strategy.clone())
                .or_insert_with(|| StrategyWeight {
                    strategy: strategy.clone(),
                    weight: 0.5,
                    success_rate: 0.0,
                    usage_count: 0,
                    last_updated: Utc::now(),
                });
            
            strategy_weight.weight = new_weight.clamp(0.0, 1.0);
            strategy_weight.usage_count += 1;
            strategy_weight.last_updated = Utc::now();
        }
        
        state.updated_at = Utc::now();
        self.save_state(&state).await?;
        Ok(())
    }

    /// Get all agent states
    pub async fn list_all_states(&self) -> Result<Vec<AgentState>> {
        let mut states = Vec::new();
        let mut dir_entries = fs::read_dir(&self.base_dir).await?;
        
        while let Some(entry) = dir_entries.next_entry().await? {
            if let Some(ext) = entry.path().extension() {
                if ext == "json" {
                    if let Some(stem) = entry.path().file_stem() {
                        if let Some(agent_id) = stem.to_str() {
                            if let Ok(Some(state)) = self.load_state(agent_id).await {
                                states.push(state);
                            }
                        }
                    }
                }
            }
        }
        
        Ok(states)
    }

    /// Get performance comparison between agents
    pub async fn get_performance_comparison(&self) -> Result<HashMap<String, PerformanceMetrics>> {
        let states = self.list_all_states().await?;
        let mut comparison = HashMap::new();
        
        for state in states {
            comparison.insert(state.agent_id, state.performance);
        }
        
        Ok(comparison)
    }

    /// Get state file path for agent
    fn get_state_file_path(&self, agent_id: &str) -> PathBuf {
        self.base_dir.join(format!("{}.json", agent_id))
    }
}

impl Default for PerformanceMetrics {
    fn default() -> Self {
        Self {
            success_rate: 0.0,
            avg_roi: 0.0,
            total_decisions: 0,
            avg_response_time_ms: 0,
            accuracy_score: 0.0,
            confidence_level: 0.5,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[tokio::test]
    async fn test_state_persistence() {
        let temp_dir = tempdir().unwrap();
        let manager = AgentStateManager::new(temp_dir.path().to_str().unwrap()).await.unwrap();
        
        let state = manager.create_state("test_agent", "investor");
        manager.save_state(&state).await.unwrap();
        
        let loaded_state = manager.load_state("test_agent").await.unwrap().unwrap();
        assert_eq!(loaded_state.agent_id, "test_agent");
        assert_eq!(loaded_state.agent_type, "investor");
    }

    #[tokio::test]
    async fn test_decision_recording() {
        let temp_dir = tempdir().unwrap();
        let manager = AgentStateManager::new(temp_dir.path().to_str().unwrap()).await.unwrap();
        
        let decision = AgentDecision {
            decision_id: "decision_1".to_string(),
            decision_type: "investment".to_string(),
            input_data: serde_json::json!({"market": "bull"}),
            output: serde_json::json!({"action": "buy"}),
            confidence: 0.8,
            outcome: None,
            decided_at: Utc::now(),
            outcome_measured_at: None,
        };
        
        manager.record_decision("test_agent", decision).await.unwrap();
        
        let state = manager.load_state("test_agent").await.unwrap().unwrap();
        assert_eq!(state.decision_history.len(), 1);
        assert_eq!(state.decision_history[0].decision_id, "decision_1");
    }
}