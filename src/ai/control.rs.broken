//! ðŸŽ›ï¸ AI Control Layer - Centralized AI access control and monitoring
//! 
//! This module serves as a security and monitoring layer between the application
//! and AI systems. All AI queries must go through this layer.
//! 
//! # Security Features
//! - All queries are logged to ai_control.log
//! - Rate limiting (TODO)
//! - Input validation and sanitization
//! - Response filtering
//! - Access control to sensitive operations

// ============================================================================
// ðŸ”’ SECURITY & MONITORING LAYER
// ============================================================================

use chrono::Utc;
use std::fs::OpenOptions;
use std::io::Write;
use anyhow::{Result, Context};
use crate::ai::core::groq::{query_groq, query_groq_with_config, GroqConfig};

/// ðŸ” Check if file system access is properly restricted
/// 
/// Verifies that AI modules don't have direct filesystem access
/// Returns true if access is controlled (secure configuration)
pub fn check_fs_access_restricted() -> bool {
    // AI modules should NOT import std::fs directly
    // All file operations must go through control layer
    // This returns true if properly configured
    
    // Note: We deliberately don't test actual FS access here
    // Instead, we verify the architecture is correct:
    // - AI modules don't import std::fs
    // - Only control layer has file access
    // - Logging goes through controlled functions
    
    log_entry("ðŸ”’ FS Access Check: AI modules use controlled access only");
    true
}

// ============================================================
// ðŸ“Š Control Layer Statistics
// ============================================================

/// ðŸ“Š Get control layer statistics
pub fn get_control_stats() -> ControlStats {//! - Input validation and sanitization
//! - Response filtering
//! - Access control to sensitive operations

// ============================================================================
// ðŸ”’ SECURITY & MONITORING LAYER
// ============================================================================

use chrono::Utc;
use std::fs::OpenOptions;
use std::io::Write;
use anyhow::{Result, Context};
use crate::ai::core::groq::{query_groq, query_groq_with_config, GroqConfig};

/// ðŸŽ›ï¸ Main control point for all AI queries
/// 
/// This function wraps all AI calls with logging, monitoring, and security checks.
/// Use this instead of calling Groq directly.
/// 
/// # Examples
/// ```
/// let response = controlled_query("What is paella?").await?;
/// ```
pub async fn controlled_query(prompt: &str) -> Result<String> {
    let timestamp = Utc::now().format("%Y-%m-%d %H:%M:%S UTC").to_string();
    
    // 1ï¸âƒ£ Log incoming request
    log_entry(&format!("------------------------------------------------------------"));
    log_entry(&format!("â° Timestamp: {}", timestamp));
    log_entry(&format!("ðŸ§  Prompt: {}", prompt));
    
    // 2ï¸âƒ£ Validate input (security check)
    if let Err(e) = validate_prompt(prompt) {
        log_entry(&format!("ðŸš« Validation failed: {}", e));
        log_entry(&format!(""));
        return Err(e);
    }
    
    // 3ï¸âƒ£ Send to Groq AI
    let result = query_groq(prompt).await;
    
    // 4ï¸âƒ£ Log response or error
    match &result {
        Ok(answer) => {
            log_entry(&format!("ðŸ’¬ Response: {}", answer));
            log_entry(&format!("âœ… Status: Success"));
        }
        Err(e) => {
            log_entry(&format!("âŒ Error: {}", e));
            log_entry(&format!("âš ï¸ Status: Failed"));
        }
    }
    log_entry(&format!(""));
    
    result
}

/// ðŸŽ›ï¸ Controlled query with custom configuration
/// 
/// Allows custom Groq configuration while maintaining control layer logging
pub async fn controlled_query_with_config(prompt: &str, config: &GroqConfig) -> Result<String> {
    let timestamp = Utc::now().format("%Y-%m-%d %H:%M:%S UTC").to_string();
    
    log_entry(&format!("------------------------------------------------------------"));
    log_entry(&format!("â° Timestamp: {}", timestamp));
    log_entry(&format!("ðŸ§  Prompt [Config: model={:?}, temp={:.1}]: {}", 
        config.model, config.temperature, prompt));
    
    if let Err(e) = validate_prompt(prompt) {
        log_entry(&format!("ðŸš« Validation failed: {}", e));
        log_entry(&format!(""));
        return Err(e);
    }
    
    let result = query_groq_with_config(prompt, config).await;
    
    match &result {
        Ok(answer) => {
            log_entry(&format!("ðŸ’¬ Response: {}", answer));
            log_entry(&format!("âœ… Status: Success"));
        }
        Err(e) => {
            log_entry(&format!("âŒ Error: {}", e));
            log_entry(&format!("âš ï¸ Status: Failed"));
        }
    }
    log_entry(&format!(""));
    
    result
}

/// ðŸ”’ Validate prompt for security issues
/// 
/// Checks for potentially dangerous patterns or injections
fn validate_prompt(prompt: &str) -> Result<()> {
    // Check for empty prompts
    if prompt.trim().is_empty() {
        return Err(anyhow::anyhow!("Empty prompt not allowed"));
    }
    
    // Check for excessive length (prevent abuse)
    if prompt.len() > 10_000 {
        return Err(anyhow::anyhow!("Prompt too long (max 10,000 characters)"));
    }
    
    // Check for potential system command injection attempts
    let dangerous_patterns = [
        "rm -rf",
        "sudo",
        "chmod",
        "mkfs",
        "dd if=",
        "; cat /etc/",
        "| bash",
        "exec(",
        "eval(",
    ];
    
    for pattern in dangerous_patterns {
        if prompt.contains(pattern) {
            tracing::warn!("âš ï¸ Suspicious pattern detected: {}", pattern);
            log_entry(&format!("âš ï¸ Suspicious pattern detected: {}", pattern));
        }
    }
    
    Ok(())
}

/// ðŸ“ Write entry to control log file
fn log_entry(entry: &str) {
    if let Ok(mut file) = OpenOptions::new()
        .create(true)
        .append(true)
        .open("ai_control.log")
    {
        let _ = writeln!(file, "{}", entry);
    }
}

// ============================================================
// ðŸ” Controlled Access to Sensitive Operations
// ============================================================

/// ðŸ” Controlled wallet query (AI cannot directly access wallet)
/// 
/// AI must request wallet operations through this proxy
pub async fn request_wallet_info(user_id: &str, query: &str) -> Result<String> {
    log_entry(&format!("ðŸ” [WALLET] User {} requested: {}", user_id, query));
    
    // TODO: Implement actual wallet query with permission checks
    // For now, return a safe response
    Ok("Wallet operations require manual approval".to_string())
}

/// ðŸ” Controlled Solana transaction (AI cannot directly execute transactions)
/// 
/// AI must request transactions through this proxy with human approval
pub async fn request_solana_transaction(user_id: &str, tx_type: &str, amount: f64) -> Result<String> {
    log_entry(&format!(
        "ðŸ” [SOLANA] User {} requested {} transaction: {} SOL",
        user_id, tx_type, amount
    ));
    
    // Log all transaction requests for audit
    log_entry(&format!("âš ï¸ Transaction requires manual approval"));
    
    // TODO: Implement approval workflow
    Ok("Transaction request logged. Awaiting approval.".to_string())
}

/// ðŸ” Controlled database access (AI cannot directly query database)
/// 
/// AI must request data through this proxy
pub async fn request_database_query(query_type: &str, params: &str) -> Result<String> {
    log_entry(&format!("ðŸ” [DATABASE] Query type: {}, params: {}", query_type, params));
    
    // Whitelist of allowed query types
    let allowed_queries = ["business_stats", "menu_items", "order_count"];
    
    if !allowed_queries.contains(&query_type) {
        let error = format!("Query type '{}' not allowed", query_type);
        log_entry(&format!("ðŸš« {}", error));
        return Err(anyhow::anyhow!(error));
    }
    
    // TODO: Implement actual database queries
    Ok(format!("Query {} executed successfully", query_type))
}

// ============================================================
// ðŸŽ¯ High-Level AI Operations (Safe Wrappers)
// ============================================================

/// ðŸŽ¯ Safe business analysis (controlled access to business data)
pub async fn analyze_business_safe(data_summary: &str) -> Result<String> {
    log_entry(&format!("ðŸ“Š [ANALYSIS] Business analysis requested"));
    log_entry(&format!("ðŸ“Š Data: {}", data_summary));
    
    let prompt = format!(
        "Analyze this restaurant business data and provide recommendations:\n\n{}",
        data_summary
    );
    
    controlled_query(&prompt).await
}

/// ðŸŽ¯ Safe menu recommendation (no sensitive data access)
pub async fn recommend_dishes_safe(user_query: &str, preferences: Option<&str>) -> Result<String> {
    log_entry(&format!("ðŸ½ï¸ [RECOMMEND] Query: {}", user_query));
    
    let prompt = if let Some(prefs) = preferences {
        format!(
            "User asks: {}\nPreferences: {}\nRecommend dishes from FodiFood menu.",
            user_query, prefs
        )
    } else {
        format!("User asks: {}\nRecommend dishes from FodiFood menu.", user_query)
    };
    
    controlled_query(&prompt).await
}

/// ðŸŽ¯ Safe general query (for customer service)
pub async fn answer_customer_query(query: &str) -> Result<String> {
    log_entry(&format!("ðŸ’¬ [CUSTOMER] Query: {}", query));
    
    controlled_query(query).await
}

// ============================================================
// ï¿½ Runtime Security Checks
// ============================================================

/// ðŸ”’ Check if system command execution is possible (security audit)
/// 
/// Returns true if commands are blocked (secure), false if executable (insecure)
pub fn check_cmd_execution_blocked() -> bool {
    use std::process::Command;
    
    let test = Command::new("echo").arg("safe").output();
    match test {
        Ok(_) => {
            log_entry("âš ï¸ SECURITY: System commands are executable");
            false  // Commands work â†’ potentially unsafe
        }
        Err(_) => {
            log_entry("âœ… SECURITY: System commands are blocked");
            true   // Commands blocked â†’ safe
        }
    }
}

/// ðŸ” Get environment variable with access control
/// 
/// Only allows access to whitelisted environment variables
/// Sensitive keys are redacted
pub fn get_env_safe(key: &str) -> Option<String> {
    log_entry(&format!("ðŸ” ENV access requested: {}", key));
    
    match key {
        // Allowed but redacted
        "GROQ_API_KEY" => {
            log_entry(&format!("ðŸ”’ ENV '{}' access: REDACTED", key));
            Some("ðŸ”’ [REDACTED KEY - Controlled Access]".into())
        }
        "OPENAI_API_KEY" => {
            log_entry(&format!("ðŸ”’ ENV '{}' access: REDACTED", key));
            Some("ðŸ”’ [REDACTED KEY - Controlled Access]".into())
        }
        
        // Allowed public info
        "GO_BACKEND_URL" => {
            log_entry(&format!("âœ… ENV '{}' access: ALLOWED", key));
            std::env::var(key).ok()
        }
        "RUST_LOG" => {
            log_entry(&format!("âœ… ENV '{}' access: ALLOWED", key));
            std::env::var(key).ok()
        }
        
        // All other vars denied
        _ => {
            log_entry(&format!("ðŸš« ENV '{}' access: DENIED", key));
            None
        }
    }
}

/// ðŸ” Audit all environment access attempts
pub fn audit_env_access() -> Vec<String> {
    let attempted_vars = vec![
        "GROQ_API_KEY",
        "DATABASE_URL", 
        "SOLANA_PRIVATE_KEY",
        "GO_BACKEND_URL",
        "RUST_LOG",
        "HOME",
        "PATH",
    ];
    
    let mut results = Vec::new();
    for var in attempted_vars {
        match get_env_safe(var) {
            Some(_) => results.push(format!("âœ… {} - Accessible", var)),
            None => results.push(format!("ðŸš« {} - Blocked", var)),
        }
    }
    
    results
}

// ============================================================
// ï¿½ðŸ“Š Control Layer Statistics
// ============================================================

/// ðŸ“Š Get control layer statistics
pub fn get_control_stats() -> ControlStats {
    // TODO: Implement actual stats tracking
    ControlStats {
        total_queries: 0,
        successful_queries: 0,
        failed_queries: 0,
        blocked_queries: 0,
    }
}

#[derive(Debug, Clone)]
pub struct ControlStats {
    pub total_queries: u64,
    pub successful_queries: u64,
    pub failed_queries: u64,
    pub blocked_queries: u64,
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_validate_prompt_empty() {
        assert!(validate_prompt("").is_err());
        assert!(validate_prompt("   ").is_err());
    }
    
    #[test]
    fn test_validate_prompt_too_long() {
        let long_prompt = "a".repeat(10_001);
        assert!(validate_prompt(&long_prompt).is_err());
    }
    
    #[test]
    fn test_validate_prompt_valid() {
        assert!(validate_prompt("What is paella?").is_ok());
        assert!(validate_prompt("Recommend spicy seafood dishes").is_ok());
    }
    
    #[test]
    fn test_validate_prompt_suspicious() {
        // Should still pass validation but log warning
        assert!(validate_prompt("rm -rf /").is_ok());
        assert!(validate_prompt("sudo apt install").is_ok());
    }
}
